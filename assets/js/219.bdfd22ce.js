(window.webpackJsonp=window.webpackJsonp||[]).push([[219],{535:function(s,t,e){"use strict";e.r(t);var a=e(4),n=Object(a.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("p",[s._v("Scrapy 是一个用于构建和管理网络爬虫的强大 Python 框架。它提供了许多工具和功能, 使你能够轻松地抓取网页上的数据, 处理和存储数据。以下是一些关于 Scrapy 库的主要特点和功能:")]),s._v(" "),t("ul",[t("li",[t("p",[t("code",[s._v("灵活性和可扩展性")]),s._v(": Scrapy 提供了一个灵活的框架, 允许你定义自己的爬虫规则和数据流程。你可以编写自定义爬虫, 处理不同网站的结构和数据。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("异步请求")]),s._v(": Scrapy 支持异步请求, 允许你同时处理多个请求, 提高了爬取效率。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("选择器")]),s._v(": Scrapy 内置了 XPath 和 CSS 选择器, 用于从网页中提取数据。这使得数据抽取变得相对容易。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("中间件")]),s._v(": Scrapy 允许你添加自定义中间件, 以执行各种操作, 如代理、用户代理伪装、请求和响应的处理等。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("数据流管道")]),s._v(": Scrapy 允许你定义数据处理管道, 以将抓取到的数据保存到不同的数据存储, 如数据库、JSON 文件、CSV 文件等。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("自动限速")]),s._v(": Scrapy 具有内置的请求限速功能, 以避免对目标网站的过度访问。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("扩展性")]),s._v(": Scrapy 的架构非常灵活, 允许你编写扩展或插件, 以添加自定义功能。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("用户文档和社区支持")]),s._v(": Scrapy 拥有丰富的用户文档和一个活跃的社区, 可以提供支持和解决问题。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("内置的调试工具")]),s._v(": Scrapy 提供了一些内置工具, 用于调试和分析爬取过程。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("定时任务")]),s._v(": 你可以使用 Scrapy 来创建定时任务, 以定期抓取网站上的数据。")])])]),s._v(" "),t("p",[s._v("Scrapy 是一个强大的爬虫框架, 适用于各种网络爬虫任务, 包括数据挖掘、数据收集、搜索引擎爬虫等。如果你需要构建一个高效且可扩展的网络爬虫应用, Scrapy 是一个值得考虑的工具。通过学习 Scrapy, 你可以更轻松地抓取和处理互联网上的数据。")]),s._v(" "),t("h2",{attrs:{id:"scrapy-工作流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#scrapy-工作流程"}},[s._v("#")]),s._v(" scrapy 工作流程")]),s._v(" "),t("p",[s._v("下方参考文章, "),t("a",{attrs:{href:"https://blog.csdn.net/weixin_44827418/article/details/107288420",target:"_blank",rel:"noopener noreferrer"}},[s._v("scrapy 爬虫框架——概念作用和工作流程 & scrapy 的入门使用"),t("OutboundLink")],1)]),s._v(" "),t("h3",{attrs:{id:"workflow"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#workflow"}},[s._v("#")]),s._v(" workflow")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/jacky1234/picArchieve@master/uPic/20231025_104805_ikfoY8.png",alt:"Scrapy架构图"}})]),s._v(" "),t("p",[s._v("其流程可以描述如下:")]),s._v(" "),t("ul",[t("li",[s._v("爬虫中起始的 url 构造成 request 对象–>爬虫中间件–>引擎–>调度器")]),s._v(" "),t("li",[s._v("调度器把 request–>引擎–>下载中间件—>下载器")]),s._v(" "),t("li",[s._v("下载器发送请求, 获取 response 响应----\x3e下载中间件----\x3e引擎—>爬虫中间件—>爬虫")]),s._v(" "),t("li",[s._v("爬虫提取 url 地址, 组装成 request 对象----\x3e爬虫中间件—>引擎—>调度器, 重复步骤 2")]),s._v(" "),t("li",[s._v("爬虫提取数据—>引擎—>管道处理和保存数据")])]),s._v(" "),t("h3",{attrs:{id:"每个模块的具体作用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#每个模块的具体作用"}},[s._v("#")]),s._v(" 每个模块的具体作用")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/jacky1234/picArchieve@master/uPic/20240429_164432_V6420h.png",alt:"scrapy module"}})]),s._v(" "),t("h2",{attrs:{id:"command"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#command"}},[s._v("#")]),s._v(" "),t("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/commands.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("command"),t("OutboundLink")],1)]),s._v(" "),t("ul",[t("li",[t("code",[s._v("scrapy startproject <tutorial>")]),s._v(": create a tutorial project")]),s._v(" "),t("li",[t("code",[s._v("scrapy crawl <quotes>")]),s._v(": This command runs the spider with name quotes")]),s._v(" "),t("li",[t("RouterLink",{attrs:{to:"/pages/048166/"}},[s._v("scrapy shell")])],1)]),s._v(" "),t("h3",{attrs:{id:"help"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#help"}},[s._v("#")]),s._v(" help")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("Scrapy "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.11")]),s._v(".0 - no active project\n\nUsage:\n  scrapy "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("command"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("options"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\nAvailable commands:\n  bench         Run quick benchmark "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("test")]),s._v("\n  fetch         Fetch a URL using the Scrapy downloader\n  genspider     Generate new spider using pre-defined templates\n  runspider     Run a self-contained spider "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("without creating a project"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  settings      Get settings values\n  shell         Interactive scraping console\n  startproject  Create new project\n  version       Print Scrapy version\n  view          Open URL "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" browser, as seen by Scrapy\n\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("more")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("      More commands available when run from project directory\n\nUse "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"scrapy <command> -h"')]),s._v(" to see "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("more")]),s._v(" info about a "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("command")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br")])]),t("h2",{attrs:{id:"api"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#api"}},[s._v("#")]),s._v(" api")]),s._v(" "),t("ul",[t("li",[t("p",[t("strong",[s._v("Crawler API")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("CrawlerProcess: CrawlerProcess 是 Scrapy 的高级 API, 用于配置和启动多个爬虫同时运行。")]),s._v(" "),t("li",[s._v("Crawler: Crawler 是一个具体的爬虫实例, 它负责处理一个网站的抓取任务。")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Spider API")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("scrapy.Spider: Spider 是一个 Scrapy 爬虫的基类, 开发者可以从这个基类继承并自定义爬虫。")]),s._v(" "),t("li",[s._v("name: 用于标识爬虫的名称。")]),s._v(" "),t("li",[s._v("start_urls: 包含爬虫起始 URL 的列表。")]),s._v(" "),t("li",[s._v("parse(): 用户自定义的解析方法, 用于处理从网页提取的数据。")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Request and Response API")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("scrapy.Request: 用于创建 HTTP 请求的类, 包括 URL、回调函数等。")]),s._v(" "),t("li",[s._v("scrapy.Response: 包含 HTTP 响应数据的类, 通常由爬虫的回调函数处理。")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Item API")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("scrapy.Item: Item 是用于封装抓取到的数据的容器, 通常定义为 Python 类, 每个字段都由 Item 的属性表示。")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Selector API")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("scrapy.Selector: Selector 是用于从 HTML 或 XML 文档中提取数据的工具, 提供了 XPath 和 CSS 选择器的支持。")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Middleware API")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("中间件(Middleware)是 Scrapy 中用于处理请求和响应的组件, 允许开发者进行自定义处理, 如 User-Agent 设置、代理、重定向等。")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Downloader API")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("scrapy.downloadermiddlewares: 提供了一系列内置的下载器中间件, 用于处理 HTTP 请求和响应的下载过程。")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Pipeline API")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("scrapy.Pipeline: Pipeline 是用于处理抓取到的数据的组件, 允许开发者定义多个数据处理步骤, 如数据清洗、存储、导出等。")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Settings API")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("scrapy.settings: 用于管理 Scrapy 爬虫的设置和配置。")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Command-line Interface (CLI)")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("Scrapy 提供了命令行工具, 允许你创建、运行和管理爬虫。")])])])]),s._v(" "),t("p",[s._v("这些是 Scrapy 中的一些主要 API 和组件, 它们允许开发者构建高效的网络爬虫, 从目标网站中提取数据。Scrapy 还提供了广泛的文档和教程, 帮助开发者学习如何使用这些 API 来构建和管理爬虫。通过这些 API, 你可以定制各种功能和操作, 以满足不同的抓取需求")]),s._v(" "),t("h2",{attrs:{id:"selector"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#selector"}},[s._v("#")]),s._v(" selector")]),s._v(" "),t("blockquote",[t("p",[s._v("Querying responses using XPath and CSS is so common that responses include two more shortcuts: response.xpath() and response.css()。 For reading more, "),t("RouterLink",{attrs:{to:"/《python》/10.module/(https://docs.scrapy.org/en/latest/topics/selectors.html#topics-selectors)"}},[s._v("click me")])],1)]),s._v(" "),t("h3",{attrs:{id:"api-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#api-2"}},[s._v("#")]),s._v(" API")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("attrib")]),s._v(": SelectorList, it returns attributes for the first matching element")])]),s._v(" "),t("p",[t("strong",[t("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/selectors.html#topics-selectors-htmlcode",target:"_blank",rel:"noopener noreferrer"}},[s._v("示例"),t("OutboundLink")],1)])]),s._v(" "),t("ul",[t("li",[t("code",[s._v('response.css("img::text").get(default="")')]),s._v(": with default value")]),s._v(" "),t("li",[t("code",[s._v('response.xpath("//title/text()").get()')])]),s._v(" "),t("li",[t("code",[s._v('response.css("title::text").get()')])]),s._v(" "),t("li",[t("code",[s._v('response.xpath("//img/@src").get()')])]),s._v(" "),t("li",[t("code",[s._v('response.css("img").xpath("@src").getall()')])]),s._v(" "),t("li",[t("code",[s._v('response.css("img::attr(src)").getall()')])]),s._v(" "),t("li",[t("code",[s._v('response.css("base").attrib["href"]')]),s._v(":  此方案只能获取到第一个匹配的元素")]),s._v(" "),t("li",[t("code",[s._v("response.xpath('//div[@id=\"images\"]/a/text()').get()")])]),s._v(" "),t("li",[t("code",[s._v("response.xpath('//div[@id=\"images\"]/a/text()').get(default='not found')")])]),s._v(" "),t("li",[s._v("CSS\n"),t("ul",[t("li",[t("code",[s._v("title::text")]),s._v(": selects children text nodes of a descendant "),t("code",[s._v("<title>")]),s._v(" element")]),s._v(" "),t("li",[t("code",[s._v("*::text")]),s._v(": selects all descendant text nodes of the current selector context\n"),t("ul",[t("li",[t("code",[s._v("#images *::text")]),s._v(": 选择 id 属性为 images 的元素的所有子元素的文本内容")])])]),s._v(" "),t("li",[t("code",[s._v("[href*=image]::attr(href)")]),s._v(': 使用属性选择器, 筛选具有 href 属性包含 "image" 的元素, 获取 href 属性值\n'),t("ul",[t("li",[t("code",[s._v("[href*=image] img::attr(src)")]),s._v(": 1. 选择 href 包含 image 的元素 2.所有子元素 "),t("code",[s._v("img")]),s._v(" 的 src 属性内容")]),s._v(" "),t("li",[t("code",[s._v("[href^='https']")]),s._v(': 选择具有以 "https" 开头的 href 属性的元素')])])])])]),s._v(" "),t("li",[s._v("复合选择\n"),t("ul",[t("li",[t("code",[s._v("response.css(\"div[class=yizhu] img[src*='bei-pic.png']::attr(onclick)\").getall()")]),s._v(":\n"),t("ul",[t("li",[t("code",[s._v("response.css()")]),s._v(" 是 Scrapy 框架中用于执行 CSS 选择器的方法, 它会返回一个 SelectorList 对象, 其中包含了匹配到的元素。")]),s._v(" "),t("li",[t("code",[s._v("div[class=yizhu] img[src*='bei-pic.png']")]),s._v(' 是 CSS 选择器, 用于选取 class 属性为 "yizhu" 的 div 元素中, 包含 src 属性值包含 "bei-pic.png" 的 img 元素。')]),s._v(" "),t("li",[t("code",[s._v("::attr(onclick)")]),s._v(" 是 CSS 伪元素语法, 用于选取 img 元素的 onclick 属性。")]),s._v(" "),t("li",[t("code",[s._v("getall()")]),s._v(" 是 SelectorList 对象的方法, 用于获取所有匹配到的元素的属性值, 并以列表的形式返回。")])])])])])]),s._v(" "),t("h3",{attrs:{id:"css"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#css"}},[s._v("#")]),s._v(" css")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("[]")]),s._v(": 指定条件")]),s._v(" "),t("li",[t("code",[s._v("::text")]),s._v(": select text nodes")]),s._v(" "),t("li",[t("code",[s._v("::attr(name)")]),s._v(": select attribute values")])]),s._v(" "),t("p",[t("strong",[s._v("Nesting selectors")])]),s._v(" "),t("blockquote",[t("p",[t("code",[s._v("response.xpath('//a[contains(@href, \"image\")]/@href')")]),s._v(': 用 contains 函数来筛选具有 href 属性包含 "image" 的元素')])]),s._v(" "),t("p",[s._v("The selection methods (.xpath() or .css()) return a list of selectors of the same type, so you can call the selection methods for those selectors too.")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" links "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" response.xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[contains(@href, \"image\")]'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" links.getall"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('\'<a href="image1.html">Name: My image 1 <br><img src="image1_thumb.jpg" alt="image1"></a>\'')]),s._v(",\n"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('\'<a href="image2.html">Name: My image 2 <br><img src="image2_thumb.jpg" alt="image2"></a>\'')]),s._v(",\n"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('\'<a href="image3.html">Name: My image 3 <br><img src="image3_thumb.jpg" alt="image3"></a>\'')]),s._v(",\n"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('\'<a href="image4.html">Name: My image 4 <br><img src="image4_thumb.jpg" alt="image4"></a>\'')]),s._v(",\n"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('\'<a href="image5.html">Name: My image 5 <br><img src="image5_thumb.jpg" alt="image5"></a>\'')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" index, "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("link")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" enumerate"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("links"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n    href_xpath "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" link.xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"@href"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(".get"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    img_xpath "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" link.xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"img/@src"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(".get"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    print"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("f"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Link number {index} points to url {href_xpath!r} and image {img_xpath!r}"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br")])]),t("h3",{attrs:{id:"xpath"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#xpath"}},[s._v("#")]),s._v(" xpath")]),s._v(" "),t("blockquote",[t("p",[t("RouterLink",{attrs:{to:"/pages/2d9e1c/"}},[s._v("jump")])],1)]),s._v(" "),t("h2",{attrs:{id:"其他"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#其他"}},[s._v("#")]),s._v(" 其他")]),s._v(" "),t("h3",{attrs:{id:"shub"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#shub"}},[s._v("#")]),s._v(" shub")]),s._v(" "),t("blockquote",[t("p",[s._v("pip3 install shub")])]),s._v(" "),t("p",[s._v("shub is the Scrapinghub(云端爬虫托管平台, 用于运行、调度和管理爬虫) command-line client. It allows you to deploy\nprojects or dependencies, schedule spiders, and retrieve scraped data or\nlogs without leaving the command line.")]),s._v(" "),t("p",[s._v("以下是一些常见的用途和操作, 你可以使用 shub 来完成:")]),s._v(" "),t("ul",[t("li",[t("p",[t("strong",[s._v("部署项目")]),s._v(": 你可以使用 shub 来将你的 Scrapy 项目部署到 Scrapinghub 平台, 以便在云端环境中运行和管理你的爬虫。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("调度爬虫")]),s._v(": 通过 shub, 你可以在 Scrapinghub 平台上调度爬虫的运行, 定义运行时间和频率。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("检索抓取的数据")]),s._v(": shub 允许你从 Scrapinghub 平台上检索已抓取的数据, 以便进一步处理或导出。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("查看日志")]),s._v(": 你可以使用 shub 来查看和分析爬虫运行时生成的日志, 以便进行故障排除和性能优化。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("管理依赖")]),s._v(": shub 还允许你管理 Scrapinghub 项目的依赖, 例如使用第三方 Python 包。")])])]),s._v(" "),t("p",[s._v("总之, shub 是 Scrapinghub 平台的命令行接口, 使你能够直接从命令行中管理和操作云端爬虫项目, 而无需离开终端界面。这对于 Scrapy 项目的部署和运维非常有用, 尤其是当你需要在云端环境中扩展和管理大规模的爬虫任务时。")]),s._v(" "),t("h3",{attrs:{id:"items"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#items"}},[s._v("#")]),s._v(" Items")]),s._v(" "),t("blockquote",[t("p",[t("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/items.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://docs.scrapy.org/en/latest/topics/items.html"),t("OutboundLink")],1)])]),s._v(" "),t("p",[t("strong",[s._v("示例")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" scrapy\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" MtimeSpider"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" MtimespiderItem\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MovieSpiderSpider")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("scrapy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Spider"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ...")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("parse")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 各种解析...")]),s._v("\n    movie_list "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//ul[@id=\"asyncRatingRegion\"]/li'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" movie_li "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" movie_list"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      item "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" MtimespiderItem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      item"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'url'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" movie_li"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'div[@class=\"mov_pic\"]/a/@href'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ...")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" item\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# next request...")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" scrapy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Request"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("new_link"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" callback"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parse"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br")])]),t("p",[t("code",[s._v("yield item")]),s._v("的作用")]),s._v(" "),t("p",[s._v("在这个 Scrapy 爬虫中, "),t("code",[s._v("yield item")]),s._v(" 的作用是将抓取到的电影信息封装成一个 MtimespiderItem 对象, 并将这个对象返回, 以供 Scrapy 框架进一步处理。具体作用如下:")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("抓取数据: 在 parse 方法中, 通过 XPath 表达式从网页中抓取电影信息, 包括电影的 URL、图片 URL、标题、导演、演员、简介、得分等信息。")])]),s._v(" "),t("li",[t("p",[s._v("创建数据项: 为了将抓取到的数据组织成结构化的形式, 创建了一个 MtimespiderItem 对象, 将抓取到的信息赋值给这个对象的属性。")])]),s._v(" "),t("li",[t("p",[s._v("返回数据项: 使用 "),t("code",[s._v("yield item")]),s._v(" 语句将 MtimespiderItem 对象返回给 Scrapy 框架。这实际上是将数据项放入 Scrapy 的管道(Pipeline)中, 以便进一步处理。")])]),s._v(" "),t("li",[t("p",[s._v("继续爬取: 在 parse 方法中, 还会继续请求下一页的链接(如果有), 并继续抓取更多电影信息。这是通过再次调用 "),t("code",[s._v("yield scrapy.Request(new_link, callback=self.parse)")]),s._v(" 来实现的。")])])]),s._v(" "),t("p",[t("code",[s._v("yield item")]),s._v(" 允许 Scrapy 异步处理抓取的数据项, 例如将数据保存到数据库、文件或进行其他处理。这种异步处理使得 Scrapy 非常高效, 因为它可以并行处理多个请求和数据项, 而不必等待每个请求的完成。这也是 Scrapy 框架的一个强大特性, 使得爬虫编写变得相对简单而高效。")]),s._v(" "),t("h3",{attrs:{id:"settings-py-配置项"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#settings-py-配置项"}},[s._v("#")]),s._v(" settings.py 配置项")]),s._v(" "),t("p",[t("strong",[s._v("示例")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Scrapy settings for first_scrapy_project project")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# For simplicity, this file contains only settings considered important or")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# commonly used. You can find more settings consulting the documentation:")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     https://docs.scrapy.org/en/latest/topics/settings.html")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html")]),s._v("\n\nBOT_NAME "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first_scrapy_project"')]),s._v("\n\nSPIDER_MODULES "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first_scrapy_project.spiders"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nNEWSPIDER_MODULE "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first_scrapy_project.spiders"')]),s._v("\n\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Crawl responsibly by identifying yourself (and your website) on the user-agent")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#USER_AGENT = "first_scrapy_project (+http://www.yourdomain.com)"')]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Obey robots.txt rules")]),s._v("\nROBOTSTXT_OBEY "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Configure maximum concurrent requests performed by Scrapy (default: 16)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#CONCURRENT_REQUESTS = 32")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Configure a delay for requests for the same website (default: 0)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# See also autothrottle settings and docs")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#DOWNLOAD_DELAY = 3")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# The download delay setting will honor only one of:")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#CONCURRENT_REQUESTS_PER_DOMAIN = 16")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#CONCURRENT_REQUESTS_PER_IP = 16")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Disable cookies (enabled by default)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#COOKIES_ENABLED = False")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Disable Telnet Console (enabled by default)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#TELNETCONSOLE_ENABLED = False")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Override the default request headers:")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#DEFAULT_REQUEST_HEADERS = {")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#    "Accept-Language": "en",')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Enable or disable spider middlewares")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# See https://docs.scrapy.org/en/latest/topics/spider-middleware.html")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#SPIDER_MIDDLEWARES = {")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#    "first_scrapy_project.middlewares.FirstScrapyProjectSpiderMiddleware": 543,')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Enable or disable downloader middlewares")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#DOWNLOADER_MIDDLEWARES = {")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#    "first_scrapy_project.middlewares.FirstScrapyProjectDownloaderMiddleware": 543,')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Enable or disable extensions")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# See https://docs.scrapy.org/en/latest/topics/extensions.html")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#EXTENSIONS = {")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#    "scrapy.extensions.telnet.TelnetConsole": None,')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Configure item pipelines")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#ITEM_PIPELINES = {")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#    "first_scrapy_project.pipelines.FirstScrapyProjectPipeline": 300,')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Enable and configure the AutoThrottle extension (disabled by default)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# See https://docs.scrapy.org/en/latest/topics/autothrottle.html")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#AUTOTHROTTLE_ENABLED = True")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# The initial download delay")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#AUTOTHROTTLE_START_DELAY = 5")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# The maximum download delay to be set in case of high latencies")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#AUTOTHROTTLE_MAX_DELAY = 60")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# The average number of requests Scrapy should be sending in parallel to")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# each remote server")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Enable showing throttling stats for every response received:")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#AUTOTHROTTLE_DEBUG = False")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Enable and configure HTTP caching (disabled by default)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#HTTPCACHE_ENABLED = True")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#HTTPCACHE_EXPIRATION_SECS = 0")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#HTTPCACHE_DIR = "httpcache"')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#HTTPCACHE_IGNORE_HTTP_CODES = []")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#HTTPCACHE_STORAGE = "scrapy.extensions.httpcache.FilesystemCacheStorage"')]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Set settings whose default value is deprecated to a future-proof value")]),s._v("\nREQUEST_FINGERPRINTER_IMPLEMENTATION "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"2.7"')]),s._v("\nTWISTED_REACTOR "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"twisted.internet.asyncioreactor.AsyncioSelectorReactor"')]),s._v("\nFEED_EXPORT_ENCODING "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"utf-8"')]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br"),t("span",{staticClass:"line-number"},[s._v("67")]),t("br"),t("span",{staticClass:"line-number"},[s._v("68")]),t("br"),t("span",{staticClass:"line-number"},[s._v("69")]),t("br"),t("span",{staticClass:"line-number"},[s._v("70")]),t("br"),t("span",{staticClass:"line-number"},[s._v("71")]),t("br"),t("span",{staticClass:"line-number"},[s._v("72")]),t("br"),t("span",{staticClass:"line-number"},[s._v("73")]),t("br"),t("span",{staticClass:"line-number"},[s._v("74")]),t("br"),t("span",{staticClass:"line-number"},[s._v("75")]),t("br"),t("span",{staticClass:"line-number"},[s._v("76")]),t("br"),t("span",{staticClass:"line-number"},[s._v("77")]),t("br"),t("span",{staticClass:"line-number"},[s._v("78")]),t("br"),t("span",{staticClass:"line-number"},[s._v("79")]),t("br"),t("span",{staticClass:"line-number"},[s._v("80")]),t("br"),t("span",{staticClass:"line-number"},[s._v("81")]),t("br"),t("span",{staticClass:"line-number"},[s._v("82")]),t("br"),t("span",{staticClass:"line-number"},[s._v("83")]),t("br"),t("span",{staticClass:"line-number"},[s._v("84")]),t("br"),t("span",{staticClass:"line-number"},[s._v("85")]),t("br"),t("span",{staticClass:"line-number"},[s._v("86")]),t("br"),t("span",{staticClass:"line-number"},[s._v("87")]),t("br"),t("span",{staticClass:"line-number"},[s._v("88")]),t("br"),t("span",{staticClass:"line-number"},[s._v("89")]),t("br"),t("span",{staticClass:"line-number"},[s._v("90")]),t("br"),t("span",{staticClass:"line-number"},[s._v("91")]),t("br"),t("span",{staticClass:"line-number"},[s._v("92")]),t("br"),t("span",{staticClass:"line-number"},[s._v("93")]),t("br")])]),t("ul",[t("li",[t("p",[t("strong",[t("code",[s._v("BOT_NAME")])]),s._v(": 这是爬虫项目的名称, 用于标识项目。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("SPIDER_MODULES")])]),s._v(" 和 "),t("strong",[t("code",[s._v("NEWSPIDER_MODULE")])]),s._v(": 这些设置用于指定爬虫模块的位置。"),t("code",[s._v("SPIDER_MODULES")]),s._v(" 指定了包含爬虫的模块, 而 "),t("code",[s._v("NEWSPIDER_MODULE")]),s._v(" 指定了新爬虫的默认模块。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("ROBOTSTXT_OBEY")])]),s._v(": 这个设置控制爬虫是否遵守网站的 "),t("code",[s._v("robots.txt")]),s._v(" 文件中定义的规则, 以确保不爬取被禁止的内容。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("CONCURRENT_REQUESTS")])]),s._v(": 这个设置指定了同时进行的最大请求数量。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("DOWNLOAD_DELAY")])]),s._v(": 用于设置请求之间的下载延迟, 以防止对服务器造成过大的负担。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("COOKIES_ENABLED")])]),s._v(": 控制是否启用 cookies, 用于模拟用户会话。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("TELNETCONSOLE_ENABLED")])]),s._v(": 控制是否启用 Telnet 控制台, 通常用于远程调试。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("DEFAULT_REQUEST_HEADERS")])]),s._v(": 可以用于设置默认的 HTTP 请求头, 例如 Accept 和 Accept-Language。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("SPIDER_MIDDLEWARES")])]),s._v(" 和 "),t("strong",[t("code",[s._v("DOWNLOADER_MIDDLEWARES")])]),s._v(": 这些设置允许启用或禁用爬虫和下载器中间件, 用于自定义请求和响应处理逻辑。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("ITEM_PIPELINES")])]),s._v(": 可以配置数据处理管道, 用于对爬取的数据进行处理和存储。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("AUTOTHROTTLE_ENABLED")])]),s._v(": 启用或禁用自动节流扩展, 以限制爬虫的请求速率。")])]),s._v(" "),t("li",[t("p",[t("strong",[t("code",[s._v("HTTPCACHE_ENABLED")])]),s._v(": 启用或禁用 HTTP 缓存, 用于缓存已下载的响应。")])]),s._v(" "),t("li",[t("p",[s._v("其他设置项可以用于配置一些扩展和特定功能, 如 Telnet 控制台、自动节流、HTTP 缓存等。")])])]),s._v(" "),t("p",[s._v("这个配置文件包含了各种设置, 可以根据具体的爬虫项目需求进行自定义配置, 以满足不同的爬取任务。")]),s._v(" "),t("h3",{attrs:{id:"数据处理管道"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#数据处理管道"}},[s._v("#")]),s._v(" "),t("a",{attrs:{href:"https://doc.scrapy.org/en/latest/topics/item-pipeline.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("数据处理管道"),t("OutboundLink")],1)]),s._v(" "),t("ul",[t("li",[t("code",[s._v("ItemAdapter")]),s._v(": 一个方便的工具, 用于处理数据项(Item)")]),s._v(" "),t("li",[t("code",[s._v("DropItem")]),s._v(": 用于在处理数据时可能抛出的异常情况")]),s._v(" "),t("li",[t("code",[s._v("process_item(self, item, spider)")]),s._v(": 数据处理管道的核心方法, 用于处理每个爬取到的数据项。它接收两个参数, "),t("code",[s._v("item")]),s._v(" 表示当前处理的数据项, "),t("code",[s._v("spider")]),s._v(" 表示当前的爬虫。")]),s._v(" "),t("li",[t("code",[s._v("def open_spider(self, spider)")]),s._v(": 这是一个特殊的方法, 用于在爬虫开始运行时执行初始化操作")]),s._v(" "),t("li",[t("code",[s._v("def close_spider(self, spider)")]),s._v(": 这是一个特殊的方法, 用于在爬虫结束时执行清理操作")])]),s._v(" "),t("h3",{attrs:{id:"debug-scrapy-script"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#debug-scrapy-script"}},[s._v("#")]),s._v(" debug scrapy script")]),s._v(" "),t("blockquote",[t("p",[t("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/debug.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://docs.scrapy.org/en/latest/topics/debug.html"),t("OutboundLink")],1)])]),s._v(" "),t("p",[s._v("运行如下 python 脚本即可。 参考"),t("a",{attrs:{href:"https://stackoverflow.com/questions/21788939/how-to-use-pycharm-to-debug-scrapy-projects",target:"_blank",rel:"noopener noreferrer"}},[s._v("链接"),t("OutboundLink")],1)]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" scrapy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" cmdline\n\ncmdline"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("execute"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"scrapy runspider gushiwen/spiders/gushi.py"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("split"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("h3",{attrs:{id:"response-不全的问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#response-不全的问题"}},[s._v("#")]),s._v(" response 不全的问题")]),s._v(" "),t("ul",[t("li",[t("p",[t("strong",[s._v("HTTP 头信息问题")]),s._v(": 有些网站可能在 HTTP 头部信息中指定了响应内容的编码或压缩方式, Scrapy 默认会尝试根据头部信息来处理响应内容。如果服务器返回的头部信息与实际内容不匹配, 可能会导致内容不完整。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("网站动态加载")]),s._v(": 如果网站使用 JavaScript 或 Ajax 请求来加载数据, Scrapy 可能只能获取到页面的初始 HTML, 而无法获取 JavaScript 动态生成的内容。您可能需要使用 Scrapy Splash(可执行的浏览器渲染引擎) 或 Selenium(自动化浏览器的工具) 等工具来处理动态加载的内容。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("响应被截断")]),s._v(": 有些网站可能会对爬虫进行检测, 并主动中断响应, 导致您无法获取完整的内容。这通常需要使用反爬虫技术来解决。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("反爬虫机制")]),s._v(": 网站可能使用反爬虫技术来检测和阻止爬虫程序, 这可能会导致响应内容不完整或无法访问。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Scrapy 设置问题")]),s._v(": 某些 Scrapy 设置可能会影响响应内容的获取。您可以检查 Scrapy 的设置, 如是否启用了下载中间件、并发请求数、下载延迟等。")])])]),s._v(" "),t("p",[s._v("为了解决响应内容不完整的问题, 您可以采取以下步骤:")]),s._v(" "),t("ul",[t("li",[s._v("确保您的 Scrapy 项目设置正确, 包括适当的下载中间件和延迟设置。")]),s._v(" "),t("li",[s._v("使用 Scrapy Splash 或 Selenium 等工具来处理动态加载的内容。")]),s._v(" "),t("li",[s._v("了解目标网站的反爬虫机制, 以采取适当的对策。")])]),s._v(" "),t("p",[s._v("如果仍然存在问题, 您可能需要详细分析目标网站的结构和行为, 以找出问题的具体原因, 并调整爬虫的配置和代码来解决问题。")]),s._v(" "),t("h3",{attrs:{id:"splash-与-scrapy"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#splash-与-scrapy"}},[s._v("#")]),s._v(" splash 与 scrapy")]),s._v(" "),t("blockquote",[t("p",[s._v("scrapy 和 splash 配合使用的过程中,  splash 充当什么角色")])]),s._v(" "),t("p",[s._v("在 Scrapy 和 Splash 配合使用的过程中, Splash 充当了一个渲染服务的角色, 用于处理动态加载的页面和 JavaScript 渲染。具体来说, Splash 用于执行 JavaScript 代码、渲染网页并返回渲染后的结果给 Scrapy, 以便 Scrapy 可以进一步分析和提取数据。")]),s._v(" "),t("p",[s._v("以下是 Splash 在 Scrapy 中的作用:")]),s._v(" "),t("ul",[t("li",[t("p",[t("strong",[s._v("JavaScript 渲染")]),s._v(": 许多现代网站使用 JavaScript 来动态加载内容, 这使得传统的静态爬取方法无法获取完整的页面数据。Splash 允许 Scrapy 发送带有 JavaScript 代码的请求, 然后渲染和执行页面上的 JavaScript, 从而获取动态生成的内容。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("处理 AJAX 请求")]),s._v(": Splash 可以模拟用户与页面的交互, 包括单击按钮、填写表单等, 以便触发页面上的 AJAX 请求。这使得 Scrapy 可以捕获通过 AJAX 加载的数据。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("渲染页面截图")]),s._v(": Splash 可以渲染页面并生成截图, 这对于调试和可视化分析非常有用。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("等待元素加载")]),s._v(": Splash 允许你设置等待条件, 以确保在提取数据之前等待特定元素或事件的加载。这对于处理页面加载延迟非常有用。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("用户代理设置")]),s._v(": Splash 支持设置用户代理, 以模拟不同类型的浏览器和设备。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("Cookie 管理")]),s._v(": 你可以在 Splash 中设置和管理 Cookies, 以模拟登录状态或维护会话。")])])]),s._v(" "),t("p",[s._v("Splash 的主要优势是能够处理动态页面, 使 Scrapy 能够访问和提取那些传统爬虫无法轻松处理的内容。它允许 Scrapy 与 JavaScript 交互, 捕获由 JavaScript 生成的数据, 从而提供了更全面的网络爬虫解决方案。当你需要爬取 JavaScript 渲染的页面时, Splash 是一个强大的工具。")]),s._v(" "),t("h2",{attrs:{id:"link"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#link"}},[s._v("#")]),s._v(" link")]),s._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://scrapy.org/",target:"_blank",rel:"noopener noreferrer"}},[s._v("scrapy"),t("OutboundLink")],1),s._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://docs.scrapy.org/en/latest/intro/tutorial.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("tutorial"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://docs.scrapy.org/en/latest/faq.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("faq"),t("OutboundLink")],1)])])]),s._v(" "),t("li",[t("a",{attrs:{href:"https://cloud.tencent.com/developer/article/1650824",target:"_blank",rel:"noopener noreferrer"}},[s._v("使用 Scrapy shell 调试一步一步开发爬虫"),t("OutboundLink")],1)]),s._v(" "),t("li",[s._v("学习项目\n"),t("ul",[t("li",[t("a",{attrs:{href:"https://github.com/jacky1234/hello_scrapy",target:"_blank",rel:"noopener noreferrer"}},[s._v("hello_scrapy"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/jacky1234/PoetryCrawler.git",target:"_blank",rel:"noopener noreferrer"}},[s._v("PoetryCrawler"),t("OutboundLink")],1)])])]),s._v(" "),t("li",[s._v("爬取动态数据\n"),t("ul",[t("li",[t("a",{attrs:{href:"https://developer.aliyun.com/article/1122665",target:"_blank",rel:"noopener noreferrer"}},[s._v("使用 Scrapy + Selenium 爬取动态渲染的页面"),t("OutboundLink")],1)])])])])])}),[],!1,null,null,null);t.default=n.exports}}]);